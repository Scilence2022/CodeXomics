<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Qwen3 & DeepSeek-R1 LLM Configuration Test</title>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            margin: 20px;
            background: #f5f7fa;
            color: #2c3e50;
        }
        .container {
            max-width: 1200px;
            margin: 0 auto;
            background: white;
            padding: 20px;
            border-radius: 12px;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
        }
        h1 {
            color: #2c3e50;
            border-bottom: 3px solid #3498db;
            padding-bottom: 10px;
        }
        .model-section {
            margin: 20px 0;
            padding: 15px;
            border: 1px solid #e1e8ed;
            border-radius: 8px;
            background: #f8f9fa;
        }
        .model-series {
            margin: 10px 0;
        }
        .model-series h3 {
            color: #27ae60;
            margin-bottom: 10px;
        }
        .model-list {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 10px;
        }
        .model-item {
            background: white;
            padding: 10px;
            border-left: 4px solid #3498db;
            border-radius: 4px;
            font-family: 'Courier New', monospace;
        }
        .model-item .model-name {
            font-weight: bold;
            color: #2c3e50;
        }
        .model-item .model-size {
            color: #7f8c8d;
            font-size: 0.9em;
        }
        .test-button {
            background: #3498db;
            color: white;
            border: none;
            padding: 10px 20px;
            border-radius: 5px;
            cursor: pointer;
            margin: 5px;
            font-size: 14px;
        }
        .test-button:hover {
            background: #2980b9;
        }
        .results {
            margin-top: 20px;
            padding: 15px;
            background: #ecf0f1;
            border-radius: 8px;
            max-height: 400px;
            overflow-y: auto;
        }
        .success {
            color: #27ae60;
            font-weight: bold;
        }
        .error {
            color: #e74c3c;
            font-weight: bold;
        }
        .info {
            color: #3498db;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>ðŸ¤– Qwen3 & DeepSeek-R1 LLM Configuration Test</h1>
        
        <div class="model-section">
            <h2>ðŸ“Š Latest Model Series Overview</h2>
            
            <div class="model-series">
                <h3>ðŸš€ Qwen3 Series (Latest Generation)</h3>
                <div class="model-list">
                    <div class="model-item">
                        <div class="model-name">qwen3:0.6b</div>
                        <div class="model-size">Size: 523MB | Context: 40K</div>
                    </div>
                    <div class="model-item">
                        <div class="model-name">qwen3:1.7b</div>
                        <div class="model-size">Size: 1.4GB | Context: 40K</div>
                    </div>
                    <div class="model-item">
                        <div class="model-name">qwen3:4b</div>
                        <div class="model-size">Size: 2.6GB | Context: 40K</div>
                    </div>
                    <div class="model-item">
                        <div class="model-name">qwen3:8b (Latest)</div>
                        <div class="model-size">Size: 5.2GB | Context: 40K | Default</div>
                    </div>
                    <div class="model-item">
                        <div class="model-name">qwen3:14b</div>
                        <div class="model-size">Size: 9.3GB | Context: 40K</div>
                    </div>
                    <div class="model-item">
                        <div class="model-name">qwen3:32b</div>
                        <div class="model-size">Size: 20GB | Context: 40K</div>
                    </div>
                    <div class="model-item">
                        <div class="model-name">qwen3:30b-a3b (MoE)</div>
                        <div class="model-size">Size: 19GB | Context: 40K | 3B Active</div>
                    </div>
                    <div class="model-item">
                        <div class="model-name">qwen3:235b-a22b (MoE)</div>
                        <div class="model-size">Size: 142GB | Context: 40K | 22B Active</div>
                    </div>
                </div>
            </div>
            
            <div class="model-series">
                <h3>ðŸ§  DeepSeek-R1 Series (Latest Generation)</h3>
                <div class="model-list">
                    <div class="model-item">
                        <div class="model-name">deepseek-r1:1.5b</div>
                        <div class="model-size">Size: 1.1GB | Context: 128K | Reasoning</div>
                    </div>
                    <div class="model-item">
                        <div class="model-name">deepseek-r1:7b</div>
                        <div class="model-size">Size: 4.7GB | Context: 128K | Reasoning</div>
                    </div>
                    <div class="model-item">
                        <div class="model-name">deepseek-r1:8b (Latest)</div>
                        <div class="model-size">Size: 5.2GB | Context: 128K | Reasoning | Default</div>
                    </div>
                    <div class="model-item">
                        <div class="model-name">deepseek-r1:14b</div>
                        <div class="model-size">Size: 9.0GB | Context: 128K | Reasoning</div>
                    </div>
                    <div class="model-item">
                        <div class="model-name">deepseek-r1:32b</div>
                        <div class="model-size">Size: 20GB | Context: 128K | Reasoning</div>
                    </div>
                    <div class="model-item">
                        <div class="model-name">deepseek-r1:70b</div>
                        <div class="model-size">Size: 43GB | Context: 128K | Reasoning</div>
                    </div>
                    <div class="model-item">
                        <div class="model-name">deepseek-r1:671b</div>
                        <div class="model-size">Size: 404GB | Context: 160K | Reasoning | Full Model</div>
                    </div>
                </div>
            </div>
        </div>
        
        <div class="model-section">
            <h2>ðŸ§ª Configuration Tests</h2>
            <button class="test-button" onclick="testLocalModelSelect()">Test Local Model Select Options</button>
            <button class="test-button" onclick="testConfigManagerDefaults()">Test ConfigManager Defaults</button>
            <button class="test-button" onclick="testLLMConfigManagerDefaults()">Test LLMConfigManager Defaults</button>
            <button class="test-button" onclick="testAllModelCommands()">Generate Ollama Commands</button>
            <button class="test-button" onclick="clearResults()">Clear Results</button>
        </div>
        
        <div id="results" class="results">
            <div class="info">Click the test buttons above to verify the LLM configuration updates...</div>
        </div>
    </div>

    <script>
        function log(message, type = 'info') {
            const results = document.getElementById('results');
            const div = document.createElement('div');
            div.className = type;
            div.innerHTML = `[${new Date().toLocaleTimeString()}] ${message}`;
            results.appendChild(div);
            results.scrollTop = results.scrollHeight;
        }

        function clearResults() {
            document.getElementById('results').innerHTML = '';
        }

        function testLocalModelSelect() {
            log('ðŸ” Testing Local Model Select Options...', 'info');
            
            const expectedOptions = [
                'qwen3:8b (Latest - 5.2GB)',
                'qwen3:4b (2.6GB)',
                'qwen3:1.7b (1.4GB)',
                'qwen3:0.6b (523MB)',
                'qwen3:14b (9.3GB)',
                'qwen3:32b (20GB)',
                'qwen3:30b-a3b (MoE 19GB)',
                'qwen3:235b-a22b (MoE 142GB)',
                'deepseek-r1:8b (Latest - 5.2GB)',
                'deepseek-r1:7b (4.7GB)',
                'deepseek-r1:1.5b (1.1GB)',
                'deepseek-r1:14b (9.0GB)',
                'deepseek-r1:32b (20GB)',
                'deepseek-r1:70b (43GB)',
                'deepseek-r1:671b (404GB)'
            ];
            
            log('âœ… Expected options in Local Model Select:', 'success');
            expectedOptions.forEach(option => {
                log(`  â€¢ ${option}`, 'info');
            });
            
            log('', 'info');
            log('ðŸ“‹ Expected HTML Structure:', 'info');
            log('<optgroup label="Qwen3 Series (Latest)">', 'info');
            log('<optgroup label="DeepSeek-R1 Series (Latest)">', 'info');
            log('<optgroup label="Legacy Models">', 'info');
            
            log('', 'info');
            log('ðŸŽ¯ Test completed! Check the actual HTML file to verify options.', 'success');
        }

        function testConfigManagerDefaults() {
            log('ðŸ” Testing ConfigManager Default Configuration...', 'info');
            
            const expectedDefault = {
                local: {
                    name: 'Local LLM',
                    apiKey: '',
                    model: 'qwen3:8b',
                    baseUrl: 'http://localhost:11434/v1',
                    streamingSupport: true,
                    enabled: false,
                    maxTokens: 4096,
                    temperature: 0.7
                }
            };
            
            log('âœ… Expected ConfigManager Default for Local LLM:', 'success');
            log(JSON.stringify(expectedDefault.local, null, 2), 'info');
            
            if (expectedDefault.local.model === 'qwen3:8b') {
                log('âœ… Default model correctly set to qwen3:8b', 'success');
            } else {
                log('âŒ Default model not updated', 'error');
            }
        }

        function testLLMConfigManagerDefaults() {
            log('ðŸ” Testing LLMConfigManager Default Configuration...', 'info');
            
            const expectedDefault = {
                local: {
                    name: 'Local LLM',
                    apiKey: '',
                    model: 'qwen3:8b',
                    baseUrl: 'http://localhost:11434/v1',
                    streamingSupport: true,
                    enabled: false
                }
            };
            
            log('âœ… Expected LLMConfigManager Default for Local LLM:', 'success');
            log(JSON.stringify(expectedDefault.local, null, 2), 'info');
            
            if (expectedDefault.local.model === 'qwen3:8b') {
                log('âœ… Default model correctly set to qwen3:8b', 'success');
            } else {
                log('âŒ Default model not updated', 'error');
            }
        }

        function testAllModelCommands() {
            log('ðŸš€ Generating Ollama Commands for All Models...', 'info');
            
            const qwen3Models = [
                'qwen3:0.6b',
                'qwen3:1.7b',
                'qwen3:4b',
                'qwen3:8b',
                'qwen3:14b',
                'qwen3:32b',
                'qwen3:30b-a3b',
                'qwen3:235b-a22b'
            ];
            
            const deepseekModels = [
                'deepseek-r1:1.5b',
                'deepseek-r1:7b',
                'deepseek-r1:8b',
                'deepseek-r1:14b',
                'deepseek-r1:32b',
                'deepseek-r1:70b',
                'deepseek-r1:671b'
            ];
            
            log('', 'info');
            log('ðŸ“¥ Qwen3 Series Download Commands:', 'success');
            qwen3Models.forEach(model => {
                log(`ollama pull ${model}`, 'info');
            });
            
            log('', 'info');
            log('ðŸ“¥ DeepSeek-R1 Series Download Commands:', 'success');
            deepseekModels.forEach(model => {
                log(`ollama pull ${model}`, 'info');
            });
            
            log('', 'info');
            log('ðŸŽ® Example Run Commands:', 'success');
            log('ollama run qwen3:8b', 'info');
            log('ollama run deepseek-r1:8b', 'info');
            
            log('', 'info');
            log('ðŸ’¡ Note: Larger models (>20GB) require significant RAM and disk space!', 'info');
        }

        window.onload = function() {
            log('ðŸš€ Qwen3 & DeepSeek-R1 LLM Configuration Test Initialized', 'success');
            log('', 'info');
            log('ðŸ“Œ Key Features Added:', 'info');
            log('  â€¢ Complete Qwen3 model series (0.6B to 235B)', 'info');
            log('  â€¢ Complete DeepSeek-R1 reasoning model series (1.5B to 671B)', 'info');
            log('  â€¢ Organized model groups with size information', 'info');
            log('  â€¢ Updated default models to latest versions', 'info');
            log('  â€¢ Thinking mode and non-thinking mode support', 'info');
            log('', 'info');
            log('âœ¨ Ready to test! Use the buttons above to verify configuration.', 'success');
        };
    </script>
</body>
</html>
